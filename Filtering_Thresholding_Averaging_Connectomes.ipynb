{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "239c7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Indentifies nodes in the the connectivity matrixes from MRI that are not connected, and removes those nodes from the matrixes\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import warnings\n",
    "\n",
    "def load_and_filter_matrices(directory_path, output_dir, identifiers):\n",
    "    # Only load specific .csv file types\n",
    "    csv_files = glob.glob(os.path.join(directory_path, '**/*tckcount_SIFT2.csv'), recursive=True)\n",
    "    matrix_lists = {identifier: [] for identifier in identifiers}\n",
    "    disconnected_nodes_dict = {identifier: set() for identifier in identifiers}  # Change to a dictionary of sets\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        for identifier in identifiers:\n",
    "            if identifier in os.path.dirname(file_path):\n",
    "                # Specify the correct delimiter\n",
    "                matrix = np.loadtxt(file_path, dtype=float, delimiter=' ')\n",
    "                G = nx.from_numpy_array(matrix)\n",
    "                if not nx.is_connected(G):\n",
    "                    warnings.warn(f\"The graph in {file_path} from directory {identifier} was not connected before thresholding.\")\n",
    "                    largest_cc = max(nx.connected_components(G), key=len)\n",
    "                    not_connected_nodes = [node for node in G.nodes if node not in largest_cc]\n",
    "                    graph_name = os.path.basename(file_path)\n",
    "                    disconnected_nodes_dict[identifier].update(not_connected_nodes)  # Add the nodes to the set\n",
    "                    \n",
    "                    # Save the disconnected nodes to a separate file only if there are any\n",
    "                    if not_connected_nodes:\n",
    "                        # Increase node number by 1\n",
    "                        not_connected_nodes = [node+1 for node in not_connected_nodes]\n",
    "                        # Include the subject name in the name of the disconnected nodes text file\n",
    "                        subject_name = os.path.dirname(file_path).split('/')[-2]\n",
    "                        disconnected_nodes_file = os.path.join(output_dir, f'disconnected_nodes_{identifier}_{subject_name}_{graph_name}.txt')\n",
    "                        np.savetxt(disconnected_nodes_file, not_connected_nodes, fmt='%d')\n",
    "                    \n",
    "                matrix_lists[identifier].append((file_path, matrix))\n",
    "    \n",
    "    for identifier, matrices in matrix_lists.items():\n",
    "        if matrices:\n",
    "            # Create a new directory for each identifier\n",
    "            identifier_dir = os.path.join(output_dir, identifier)\n",
    "            os.makedirs(identifier_dir, exist_ok=True)\n",
    "            for file_path, matrix in matrices:\n",
    "                # Remove the corresponding rows and columns from the matrix\n",
    "                matrix = np.delete(matrix, list(disconnected_nodes_dict[identifier]), axis=0)\n",
    "                matrix = np.delete(matrix, list(disconnected_nodes_dict[identifier]), axis=1)\n",
    "                # Save the filtered matrices in the newly created directories\n",
    "                subject_name = os.path.dirname(file_path).split('/')[-2]\n",
    "                atlas_name = os.path.basename(file_path).split('_')[0]\n",
    "                study_name = file_path.split('/')[-4]\n",
    "                study_dir = os.path.join(identifier_dir, study_name)\n",
    "                os.makedirs(study_dir, exist_ok=True)\n",
    "                output_file_path = os.path.join(study_dir, f'filtered_{subject_name}_{atlas_name}.csv')\n",
    "                np.savetxt(output_file_path, matrix, delimiter=',')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c74162a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Threshold all filtered connectivity matrices to the highest minimal edge density across all the graphs\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import warnings\n",
    "\n",
    "def threshold_network(directory_path, output_dir):\n",
    "    csv_files = glob.glob(os.path.join(directory_path, '**', '*filtered*connectome*'), recursive=True)\n",
    "    min_edge_density = 0\n",
    "    individual_min_edge_densities = []  # List to store individual minimum edge densities\n",
    "\n",
    "    # First pass: Determine the minimal edge density to remain connected across all graphs\n",
    "    for file_path in csv_files:\n",
    "        matrix = np.loadtxt(file_path, dtype=float, delimiter=',')\n",
    "        G = nx.from_numpy_array(matrix)\n",
    "        \n",
    "        atlas_output_dir = os.path.join(output_dir, os.path.basename(os.path.dirname(file_path)))\n",
    "        os.makedirs(atlas_output_dir, exist_ok=True)\n",
    "        \n",
    "        if not nx.is_connected(G):\n",
    "            warnings.warn(f\"The graph in {file_path} was not connected before thresholding.\")\n",
    "            largest_cc = max(nx.connected_components(G), key=len)\n",
    "            not_connected_nodes = [node for node in G.nodes if node not in largest_cc]\n",
    "            \n",
    "            unconnected_file_path = os.path.join(atlas_output_dir, os.path.basename(file_path).replace('.csv', '_INITIAL_UNconnected_nodes.txt'))\n",
    "            np.savetxt(unconnected_file_path, not_connected_nodes, fmt='%d')\n",
    "            \n",
    "        threshold = 0\n",
    "        while nx.is_connected(G):\n",
    "            threshold += 1\n",
    "            matrix[matrix < threshold] = 0\n",
    "            G = nx.from_numpy_array(matrix)\n",
    "\n",
    "            if not nx.is_connected(G):\n",
    "                break\n",
    "\n",
    "        threshold -= 1\n",
    "        edge_density = nx.density(G)\n",
    "        min_edge_density = max(min_edge_density, edge_density) #this needs to be max to avoid disconnection\n",
    "\n",
    "        # Save individual minimum edge density and corresponding graph name\n",
    "        individual_min_edge_densities.append([os.path.basename(file_path), edge_density])\n",
    "\n",
    "    # Save the final min_edge_density to a separate CSV file\n",
    "    directory_name = os.path.basename(directory_path)\n",
    "    np.savetxt(os.path.join(output_dir, f\"{directory_name}_min_edge_density.csv\"), [min_edge_density], delimiter=',')\n",
    "\n",
    "    # Save individual minimum edge densities to a separate CSV file\n",
    "    np.savetxt(os.path.join(output_dir, f\"{directory_name}_individual_min_edge_densities.csv\"), individual_min_edge_densities, delimiter=',', fmt='%s')\n",
    "\n",
    "\n",
    "    # Second pass: Threshold all the graphs to the highest minimal edge density across all the graphs\n",
    "    for file_path in csv_files:\n",
    "        matrix = np.loadtxt(file_path, dtype=float, delimiter=',')\n",
    "        G = nx.from_numpy_array(matrix)\n",
    "        \n",
    "        atlas_name = os.path.basename(os.path.dirname(file_path))\n",
    "        atlas_output_dir = os.path.join(output_dir, atlas_name)\n",
    "        os.makedirs(atlas_output_dir, exist_ok=True)\n",
    "\n",
    "        \n",
    "        threshold = 0\n",
    "        while nx.is_connected(G) and nx.density(G) > (1.05 * min_edge_density): # this needs to be larger than 1 to avoid disconnection\n",
    "            threshold += 1\n",
    "            matrix[matrix < threshold] = 0\n",
    "            temp_G = nx.from_numpy_array(matrix)\n",
    "\n",
    "            if not nx.is_connected(temp_G):\n",
    "                print(f\"Error: The graph in {file_path} became disconnected when thresholded to edge density {nx.density(G)}.\")\n",
    "                break\n",
    "\n",
    "            G = temp_G\n",
    "    \n",
    "\n",
    "         # Save the thresholded matrix to a new CSV file in the output directory\n",
    "        SCM_filename = os.path.splitext(os.path.basename(file_path))[0] + \"_threshold_SCM.csv\"\n",
    "        np.savetxt(os.path.join(atlas_output_dir, SCM_filename), matrix, delimiter=',')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdf23b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create an averaged connectivity matrix across subjects\"\"\"\n",
    "def average_matrices(path, averaged_data_path):\n",
    "    files = glob.glob(os.path.join(path, '**/*SCM.csv'), recursive=True)\n",
    "    for subfolder in os.listdir(path):\n",
    "        subfolder_path = os.path.join(path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            matrix_list = []\n",
    "            for file_path in files:\n",
    "                if subfolder in os.path.dirname(file_path):\n",
    "                    matrix = np.loadtxt(file_path, dtype=float, delimiter=',')\n",
    "                    # Add this line after reading the matrix from the file\n",
    "                    if matrix.shape == (445, 445):\n",
    "                        print(f\"The matrix in {file_path} has the dimensions 445 x 445\")\n",
    "                    matrix_list.append(matrix)\n",
    "            if matrix_list:\n",
    "                averaged_matrix = np.mean(matrix_list, axis=0)\n",
    "                averaged_data_subfolder_path = os.path.join(averaged_data_path, subfolder)\n",
    "                os.makedirs(averaged_data_subfolder_path, exist_ok=True)\n",
    "                np.savetxt(os.path.join(averaged_data_subfolder_path, f'averaged_Schaefer_{subfolder}_SCM.csv'), \n",
    "                           averaged_matrix,\n",
    "                           delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a1a8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"saves edge density of all averaged SCM matrices to a file\"\"\"\n",
    "\n",
    "def check_edge_density(directory_path):\n",
    "    # Get all .csv files in the directory and its subdirectories\n",
    "    csv_files = glob.glob(os.path.join(directory_path, '**/*.csv'), recursive=True)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(directory_path, 'Averaged_edge_densities.txt')\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        for file_path in csv_files:\n",
    "            # Load the matrix\n",
    "            matrix = np.loadtxt(file_path, dtype=float, delimiter=',')\n",
    "            \n",
    "            # Create a graph from the matrix\n",
    "            G = nx.from_numpy_array(matrix)\n",
    "            \n",
    "            # Calculate the edge density\n",
    "            edge_density = nx.density(G)\n",
    "            \n",
    "            # Write the file path and edge density to the output file\n",
    "            f.write(f\"{file_path}: {edge_density}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e636e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Average the individual thresholded matrices\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def average_matrices(path, averaged_data_path, *identifiers): #specify the number of node in each parcellation \n",
    "    files = glob.glob(os.path.join(path, '**/*SCM.csv'), recursive=True)\n",
    "    \n",
    "    matrix_lists = {identifier: [] for identifier in identifiers}\n",
    "    averaged_data_paths = {identifier: os.path.join(averaged_data_path, identifier) for identifier in identifiers}\n",
    "    \n",
    "    for file_path in files:\n",
    "        for identifier in identifiers:\n",
    "            if identifier in os.path.dirname(file_path):\n",
    "                matrix = np.loadtxt(file_path, dtype=float, delimiter=',')\n",
    "                matrix_lists[identifier].append(matrix)\n",
    "\n",
    "    for identifier in identifiers:\n",
    "        os.makedirs(averaged_data_paths[identifier], exist_ok=True)\n",
    "        if matrix_lists[identifier]:\n",
    "            averaged_matrix = sum(matrix_lists[identifier]) / len(matrix_lists[identifier])\n",
    "            np.savetxt(os.path.join(averaged_data_paths[identifier], f'averaged_Schaefer_{identifier}_SCM.csv'), \n",
    "                       averaged_matrix,\n",
    "                       delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
